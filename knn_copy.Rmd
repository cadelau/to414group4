---
title: "naman trying knn"
author: "Naman Gupta"
date: "4/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# tune on only the new train set, dont touch new test set

```{r}
library(class)
library(gmodels)
library(caret)
library(C50)
library(irr)
# library(ROCR)
library(ipred)
library(randomForest)
```

```{r}
# Set the same seed
set.seed(123)
df <- read.csv("online_shoppers_intention.csv")

rows <- sample(nrow(df))
shopping <- df[rows,]

# This is roughly a 70/30 train/test split
# Only use the train data to tune and improve models right now
shopping_train <- shopping[1:8630,]
shopping_test_DNU <- shopping[8631:12330,]

shopping_train$WeekendD <- as.numeric(shopping_train$Weekend)
shopping_train$RevenueD <- as.numeric(shopping_train$Revenue)
shopping_train$Weekend <- shopping_train$WeekendD
shopping_train$Revenue <- as.factor(shopping_train$RevenueD)
shopping_train$WeekendD <- NULL
shopping_train$RevenueD <- NULL

shopping_train$NewVisitor <- ifelse(shopping_train$VisitorType == "New_Visitor",1,0)
shopping_train$VisitorType <- NULL
shopping_train$HolidaySeason <- ifelse(shopping_train$Month == "Oct" | shopping_train$Month == "Nov" | shopping_train$Month == "Dec",1,0)
shopping_train$Month <- NULL
summary(shopping_train)
shopping_use <- shopping_train

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
shopping_n <- as.data.frame(lapply(shopping_train[-16], normalize)) #started at column 2, because no point in normalizing the binary "outcome"

```

## I think this is the only chunk I changed but I'm not 100% sure
```{r }
kvals = c(1:15, seq(20, 50, 10))
shopping_train1 <- shopping_n[1:7000, ] #keep rest rows for train
shopping_test <- shopping_n[7001:nrow(shopping_n), ] #keep 1000 rows for test
shopping_train_labels <- shopping_train[1:7000, 16]
shopping_test_labels <- shopping_train[7001:nrow(shopping_n), 16]

library(FNN)

# I'm just using the test set to choose a K. The K is different based on if you want to select it from your kappa or test error, but both are below.
knnTestErr = vector(length = length(kvals))
kappa = vector(length = length(kvals))
for (i in 1:length(kvals)) {
  shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=kvals[i])
  shopping_test_pred <- factor(shopping_test_pred, levels=c("0", "1"))
  knnTestErr[i] = mean(shopping_test_pred != shopping_test_labels)
  kappa[i] = confusionMatrix(shopping_test_pred, shopping_test_labels)[[3]][[2]]
}
best_t_acc = kvals[which.min(knnTestErr)];best_t_acc # 
best_t_kappa = kvals[which.max(kappa)];best_t_kappa

plot(knnTestErr ~ kvals, type = "b")
plot(kappa ~ kvals, type = "b")
```

```{r}
# define training control
train_control<- trainControl(method="cv", number=5)

# set the range for k
k_range = data.frame( k = seq(1,300,10))

# train the model 
res_CV_KNN <- train(mpg01 ~ horsepower + weight + acceleration,
             method     = "knn",
             preProcess = c("center","scale"),
             tuneGrid   = k_range,
             trControl  = train_control,
             metric     = "Accuracy",
             data       = Auto_new)
```



```{r}
shopping_train1 <- shopping_n[1:7000, ] #keep rest rows for train
shopping_test <- shopping_n[7001:nrow(shopping_n), ] #keep 1000 rows for test
shopping_train_labels <- shopping[1:7000, 16]
shopping_test_labels <- shopping[7001:nrow(shopping_n), 16]

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=3)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")
shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=11)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=31)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=51)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=101)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=sqrt(nrow(shopping)))

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

shopping_test_pred <- knn(train = shopping_train1, test = shopping_test,
                      cl = shopping_train_labels, k=151)

CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)

confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")
```

```{r}
folds <- createFolds(shopping_use$Revenue, k = 10)
shopping_use_train <- shopping_use[1:7000, ] #keep rest rows for train
shopping_use_test <- shopping_use[7001:nrow(shopping_use), ] #keep 100 rows for test

shopping_use_train_labels <- shopping_use[1:7000, 16]
shopping_use_test_labels <- shopping_use[7001:nrow(shopping_use), 16]

shopping_use_model <- knn(train = shopping_use_train, test = shopping_use_test,
                      cl = shopping_use_train_labels, k=53)
cv_results <- lapply(folds, function(x) {
  shopping_use_train <- shopping_use[x, ]
  shopping_use_test <- shopping_use[-x, ]
  shopping_use_model <- knn(train = shopping_use_train, test = shopping_use_test,
                      cl = shopping_use_train_labels, k=11)
  shopping_use_pred <- predict(shopping_use_model, shopping_use_test)
  shopping_use_actual <- shopping_use_test$Revenue
  kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
  return(kappa)
})

str(cv_results)
mean(unlist(cv_results))
```

```{r}
shopping_use_train <- shopping_use[1:7000, ] #keep rest rows for train
shopping_use_test <- shopping_use[7001:nrow(shopping_use), ] #keep 100 rows for test

shopping_use_train_labels <- shopping_use[1:7000, 16]
shopping_use_test_labels <- shopping_use[7001:nrow(shopping_use), 16]

trControl <- trainControl(method  = "cv",
                          number  = 5)

fit <- train(Revenue ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k = 1:10),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = shopping_use)

fit
```


# IGNORE FOR NOW
```{r}
confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

#Using Z-Score Normalization
shopping_z <- as.data.frame(scale(shopping[-16]))
shopping_train <- shopping_z[4001:nrow(shopping), ]; shopping_test <- shopping_z[1:4000, ]  
shopping_test_pred <- knn(train = shopping_train, test = shopping_test,
                      cl = shopping_train_labels, k=21)
CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)
confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1")

# Partioning Data Randomly
in_train <- createDataPartition(shopping$Revenue, p = 0.7, list = FALSE)
shopping_train <- shopping_n[in_train, ]
shopping_test <- shopping_n[-in_train, ]
shopping_train_labels <- shopping[in_train, 1]
shopping_test_labels <- shopping[-in_train, 1]
shopping_test_pred <- knn(train = shopping_train, test = shopping_test, cl = c("0","1"), k=13)
CrossTable(x = shopping_test_labels, y = shopping_test_pred, 
           prop.chisq=FALSE)
confusionMatrix(shopping_test_pred, shopping_test_labels, positive = "1") # outputs a bunch of different statistics, accuracy, f score, balance accuracy
```

